{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALU_Net.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVelzqp4H3y/oXTF55rLqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domschl/ALU_Net/blob/main/ALU_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XijwVpR4s0sQ"
      },
      "source": [
        "\"\"\" A neural net that tries to become an ALU (arithmetic logic unit) \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv54Aqp9s_gs"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, regularizers, callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoLypnLqxL4p"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "try: # Colab instance?\n",
        "    from google.colab import drive\n",
        "    is_colab = True\n",
        "except: # Not? ignore.\n",
        "    is_colab = False\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0TucwitE4T"
      },
      "source": [
        "class GenSamplesALU():\n",
        "    \"\"\" Generate training data for all ALU operations \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model_ops = [\"+\", \"-\", \"*\", \"/\", \"%\",\n",
        "                          \"AND\", \"OR\", \"XOR\", \">\", \"<\", \"=\", \"!=\"]\n",
        "        self.model_dis = [10, 10, 10, 10, 10, 10,   10,  10,   10, 10, 10, 10]\n",
        "        self.model_funcs = [self.add_smpl, self.diff_smpl, self.mult_smpl,\n",
        "                            self.div_smpl, self.mod_smpl, self.and_smpl,\n",
        "                            self.bor_smpl, self.xor_smpl, self.greater_smpl,\n",
        "                            self.lesser_smpl, self.eq_smpl, self.neq_smpl]\n",
        "        self.bit_count = 15\n",
        "        self.all_bits_one = 0x7fffffff\n",
        "        self.true_vect = self.all_bits_one\n",
        "        self.false_vect = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def int_to_binary_vect(num_int, num_bits=8):\n",
        "        \"\"\" get a binary encoded vector of n of bit-lenght nm \"\"\"\n",
        "        num_vect = np.zeros(num_bits, dtype=np.float32)\n",
        "        for i in range(0, num_bits):\n",
        "            if num_int & (2**i) != 0:\n",
        "                num_vect[i] = 1.0\n",
        "        return num_vect\n",
        "\n",
        "    @staticmethod\n",
        "    def get_random_bits(bits):\n",
        "        \"\"\" get bits random int 0...2**bits-1 \"\"\"\n",
        "        return random.randint(0, 2**bits-1)\n",
        "\n",
        "    def op_string_to_index(self, op_string):\n",
        "        \"\"\" transform op_string (e.g. '+' -> 0) into corresponding index \"\"\"\n",
        "        for i in range(0, len(self.model_ops)):\n",
        "            if self.model_ops[i] == op_string:\n",
        "                return i\n",
        "        return -1\n",
        "\n",
        "    def get_data_point(self, equal_distrib=False, short_math=False):\n",
        "        \"\"\" Get a random example for on ALU operation for training \"\"\"\n",
        "        result = -1\n",
        "        op1 = self.get_random_bits(self.bit_count)\n",
        "        op2 = self.get_random_bits(self.bit_count)\n",
        "        if equal_distrib:\n",
        "            op_index = random.randint(0, len(self.model_ops)-1)\n",
        "        else:\n",
        "            rx = 0\n",
        "            for md in self.model_dis:\n",
        "                rx += md\n",
        "            rrx = random.randint(0, rx)\n",
        "            rx = 0\n",
        "            op_index = 0\n",
        "            for op_index in range(0, len(self.model_ops)):\n",
        "                rx += self.model_dis[op_index]\n",
        "                if rx > rrx:\n",
        "                    break\n",
        "        return self.encode_op(op1, op2, op_index, short_math)\n",
        "\n",
        "    def encode_op(self, op1, op2, op_index, short_math=False):\n",
        "        \"\"\" turn two ints and operation into training data \"\"\"\n",
        "        result = self.model_funcs[op_index](op1, op2, short_math)\n",
        "        sym = f\"{op1}{self.model_ops[op_index]}{op2}={result}\"\n",
        "        inp = np.concatenate(\n",
        "            [self.int_to_binary_vect(op1, num_bits=16),\n",
        "             self.int_to_binary_vect(op_index, num_bits=4),\n",
        "             self.int_to_binary_vect(op2, num_bits=16)])\n",
        "        oup = self.int_to_binary_vect(result, num_bits=32)\n",
        "        return inp, oup, result, op_index, sym\n",
        "\n",
        "    @staticmethod\n",
        "    def add_smpl(op1, op2, _):\n",
        "        \"\"\" addition training example \"\"\"\n",
        "        result = op1+op2\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def diff_smpl(op1, op2, _):\n",
        "        \"\"\" subtraction training example \"\"\"\n",
        "        if op2 > op1:\n",
        "            op2, op1 = op1, op2\n",
        "        result = op1-op2\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def mult_smpl(op1, op2, short_math=False):\n",
        "        \"\"\" multiplication training example \"\"\"\n",
        "        if short_math:\n",
        "            op1 = op1 % 1000\n",
        "            op2 = op2 % 1000\n",
        "        result = op1*op2\n",
        "        return result\n",
        "\n",
        "    def div_smpl(self, op1, op2, _):\n",
        "        \"\"\" integer division training example \"\"\"\n",
        "        while op2 == 0:\n",
        "            op2 = self.get_random_bits(self.bit_count)\n",
        "        if op1 < op2 and random.randint(0, 2) != 0:\n",
        "            if op1 != 0:\n",
        "                op1, op2 = op2, op1\n",
        "        result = op1//op2\n",
        "        return result\n",
        "\n",
        "    def mod_smpl(self, op1, op2, _):\n",
        "        \"\"\" modulo (remainder) training example \"\"\"\n",
        "        while op2 == 0:\n",
        "            op2 = self.get_random_bits(self.bit_count)\n",
        "        if op1 < op2 and random.randint(0, 2) != 0:\n",
        "            if op1 != 0:\n",
        "                op1, op2 = op2, op1\n",
        "        result = op1 % op2\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def and_smpl(op1, op2, _):\n",
        "        \"\"\" bitwise AND training example \"\"\"\n",
        "        result = op1 & op2\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def bor_smpl(op1, op2, _):\n",
        "        \"\"\" bitwise OR training example \"\"\"\n",
        "        result = op1 | op2\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def xor_smpl(op1, op2, _):\n",
        "        \"\"\" bitwise XOR training example \"\"\"\n",
        "        result = op1 ^ op2\n",
        "        return result\n",
        "\n",
        "    def greater_smpl(self, op1, op2, _):\n",
        "        \"\"\" integer comparisation > training example \"\"\"\n",
        "        if op1 > op2:\n",
        "            result = self.true_vect\n",
        "        else:\n",
        "            result = self.false_vect\n",
        "        return result\n",
        "\n",
        "    def lesser_smpl(self, op1, op2, _):\n",
        "        \"\"\" integer comparisation < training example \"\"\"\n",
        "        if op1 < op2:\n",
        "            result = self.true_vect\n",
        "        else:\n",
        "            result = self.false_vect\n",
        "        return result\n",
        "\n",
        "    def eq_smpl(self, op1, op2, _):\n",
        "        \"\"\" integer comparisation == training example \"\"\"\n",
        "        if random.randint(0, 1) == 0:  # create more cases\n",
        "            op2 = op1\n",
        "        if op1 == op2:\n",
        "            result = self.true_vect\n",
        "        else:\n",
        "            result = self.false_vect\n",
        "        return result\n",
        "\n",
        "    def neq_smpl(self, op1, op2, _):\n",
        "        \"\"\" integer comparisation != training example \"\"\"\n",
        "        if random.randint(0, 1) == 0:  # create more cases\n",
        "            op2 = op1\n",
        "        if op1 != op2:\n",
        "            result = self.true_vect\n",
        "        else:\n",
        "            result = self.false_vect\n",
        "        return result\n",
        "\n",
        "    def create_data_point(self, op1, op2, op_string):\n",
        "        \"\"\" create training data from given ints op1, op2 and op_string \"\"\"\n",
        "        op_index = self.op_string_to_index(op_string)\n",
        "        if op_index == -1:\n",
        "            print(f\"Invalid operation {op_string}\")\n",
        "            return np.array([]), np.array([]), -1, -1, None\n",
        "        return self.encode_op(op1, op2, op_index)\n",
        "\n",
        "    def create_training_data(self, samples=10000, short_math=False):\n",
        "        \"\"\" create a number of training samles \"\"\"\n",
        "        x, y, _, _, _ = self.get_data_point()\n",
        "        dpx = np.zeros((samples, len(x)), dtype=np.float32)\n",
        "        dpy = np.zeros((samples, len(y)), dtype=np.float32)\n",
        "        print(f\"Creating {samples} datasets (. = 1000 progress)\")\n",
        "        for i in range(0, samples):\n",
        "            if (i+1) % 1000 == 0:\n",
        "                print(\".\", end=\"\")\n",
        "                sys.stdout.flush()\n",
        "                if (i+1) % 100000 == 0:\n",
        "                    print()\n",
        "            x, y, _, _, _ = self.get_data_point(\n",
        "                equal_distrib=False, short_math=short_math)\n",
        "            dpx[i, :] = x\n",
        "            dpy[i, :] = y\n",
        "        print()\n",
        "        return dpx, dpy\n",
        "\n",
        "    @staticmethod\n",
        "    def decode_results(result_int_vects):\n",
        "        \"\"\" take an array of 32-float results from neural net and convert to ints \"\"\"\n",
        "        for vect in result_int_vects:\n",
        "            result_vect_ints = []\n",
        "            if (len(vect) != 32):\n",
        "                print(f\"Ignoring unexpected vector of length {len(vect)}\")\n",
        "            else:\n",
        "                int_result = 0\n",
        "                for i in range(0, 32):\n",
        "                    if vect[i] > 0.5:\n",
        "                        int_result += 2**i\n",
        "                result_vect_ints.append(int_result)\n",
        "        return result_vect_ints\n",
        "\n",
        "    def check_results(self, model, samples=1000, short_math=False):\n",
        "        \"\"\" Run a number of tests on trained model \"\"\"\n",
        "        ok = 0\n",
        "        err = 0\n",
        "        operr = [0]*len(self.model_ops)\n",
        "        opok = [0]*len(self.model_ops)\n",
        "        for _ in range(0, samples):\n",
        "            x, _, z, op, s = self.get_data_point(\n",
        "                equal_distrib=True, short_math=short_math)\n",
        "            res = self.decode_results(model.predict(np.array([x])))\n",
        "            if res[0] == z:\n",
        "                ok += 1\n",
        "                opok[op] += 1\n",
        "                r = \"OK\"\n",
        "            else:\n",
        "                err += 1\n",
        "                operr[op] += 1\n",
        "                r = \"Error\"\n",
        "                print(f\"{s} == {res[0]}: {r}\")\n",
        "                print(bin(res[0]))\n",
        "                print(bin(z))\n",
        "        opsum = ok+err\n",
        "        if opsum == 0:\n",
        "            opsum = 1\n",
        "        print(f\"Ok: {ok}, Error: {err} -> {ok/opsum*100.0}%\")\n",
        "        for i in range(0, len(self.model_ops)):\n",
        "            opsum = opok[i]+operr[i]\n",
        "            if opsum == 0:\n",
        "                opsum = 1\n",
        "            self.model_dis[i] = int(operr[i]/opsum*100)+10\n",
        "            print(\n",
        "                f\"OP{self.model_ops[i]}: Ok: {opok[i]}, Error: {operr[i]}\", end=\"\")\n",
        "            print(f\" -> {opok[i]/opsum*100.0}%\")\n",
        "        print(self.model_ops)\n",
        "        print(self.model_dis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSdpsHyfti96"
      },
      "source": [
        "def create_load_model(model_file='math_model', start_fresh=False):\n",
        "    \"\"\" Create of load a model \"\"\"\n",
        "    if model_file is None or not os.path.exists(model_file) or start_fresh:\n",
        "        regu1 = 1e-8\n",
        "        regu2 = 1e-8\n",
        "        neurons = 368\n",
        "        inputs = keras.Input(shape=(36,))  # depends on encoding of op-code!\n",
        "\n",
        "        shaper = layers.Reshape(target_shape=(36, 1,), input_shape=(36,))\n",
        "        rinp = shaper(inputs)  # x0)\n",
        "        d1 = layers.Conv1D(filters=48, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        x1 = d1(rinp)\n",
        "        d2 = layers.Conv1D(filters=64, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        x2 = d2(x1)\n",
        "        d3 = layers.Conv1D(filters=128, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        x3 = d3(x2)\n",
        "        d4 = layers.Conv1D(filters=128, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        x4 = d4(x3)\n",
        "        d5 = layers.Conv1D(filters=128, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        x5 = d5(x4)\n",
        "        d6 = layers.Conv1D(filters=128, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        x6 = d6(x5)\n",
        "        d7 = layers.Conv1D(filters=128, kernel_size=6, kernel_regularizer=regularizers.l2(\n",
        "            regu1), activation=\"relu\")\n",
        "        xcvl = d7(x6)\n",
        "        flatter = layers.Flatten()\n",
        "        xf = flatter(xcvl)\n",
        "        de1 = layers.Dense(neurons, kernel_regularizer=regularizers.l2(\n",
        "            regu2), activation=\"relu\")\n",
        "        xe1 = de1(xf)\n",
        "\n",
        "        df1 = layers.Dense(neurons, kernel_regularizer=regularizers.l2(\n",
        "            regu2), activation=\"relu\")\n",
        "        xf1 = df1(inputs)\n",
        "        df2 = layers.Dense(neurons, kernel_regularizer=regularizers.l2(\n",
        "            regu2), activation=\"relu\")\n",
        "        xf2 = df2(xf1)\n",
        "        df3 = layers.Dense(neurons, kernel_regularizer=regularizers.l2(\n",
        "            regu2), activation=\"relu\")\n",
        "        xf3 = df3(xf2)\n",
        "\n",
        "        con = layers.Concatenate()\n",
        "        xcon = con([xe1, xf3])\n",
        "        dc1 = layers.Dense(neurons, kernel_regularizer=regularizers.l2(\n",
        "            regu2), activation=\"relu\")\n",
        "        xc1 = dc1(xcon)\n",
        "\n",
        "        de2 = layers.Dense(32, activation=\"sigmoid\")\n",
        "        outputs = de2(xc1)\n",
        "        model = keras.Model(inputs=inputs, outputs=outputs, name=\"maths\")\n",
        "        # , metrics=[\"accuracy\"])\n",
        "        model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
        "        print(\"Compiling new model\")\n",
        "    else:\n",
        "        model = tf.keras.models.load_model(model_file)\n",
        "        print(\"Continuing training from existing model\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONZ9m9tbtnoO"
      },
      "source": [
        "def math_train(model, x, Y, batch_size=8192, epochs=5000, model_file='math_model'):\n",
        "    \"\"\" Training loop \"\"\"\n",
        "    interrupted = False\n",
        "    tensorboard_callback = callbacks.TensorBoard(\n",
        "        log_dir=\"./logs\",\n",
        "        histogram_freq=1,\n",
        "        write_images=1,\n",
        "        update_freq='batch')\n",
        "    try:\n",
        "        model.fit(x, Y, batch_size=batch_size, epochs=epochs,\n",
        "                  validation_split=0.03, verbose=2, callbacks=[tensorboard_callback])\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\")\n",
        "        print(\"\")\n",
        "        print(\"---------INTERRUPT----------\")\n",
        "        print(\"\")\n",
        "        print(\"Training interrupted\")\n",
        "        interrupted = True\n",
        "    finally:\n",
        "        print(f\"Saving last model to {model_file}... \", end=\"\")\n",
        "        if model_file is not None:\n",
        "            model.save(model_file)\n",
        "        print(\"Done.\")\n",
        "        return interrupted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0SfAQMUvGYF"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "380NmaHT7FqW"
      },
      "source": [
        "save_model = True\n",
        "if is_colab:\n",
        "    mountpoint='/content/drive'\n",
        "    root_path='/content/drive/My Drive'\n",
        "    if not os.path.exists(root_path):\n",
        "        drive.mount(mountpoint)\n",
        "    if not os.path.exists(root_path):\n",
        "        print(\"Something went wrong with Google Drive access. Cannot model to google drive.\")\n",
        "        save_model = False\n",
        "else:\n",
        "    root_path='.'\n",
        "\n",
        "if save_model:\n",
        "    project_path=os.path.join(root_path,f\"Colab Notebooks/ALU_Net\")\n",
        "    model_file=os.path.join(project_path,'math_model')\n",
        "else:\n",
        "    model_file=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNMLz7xg8c86"
      },
      "source": [
        "print(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn6F0aI_tsXZ"
      },
      "source": [
        "math_data = GenSamplesALU()\n",
        "for _ in range(0, 100):\n",
        "    x_train, Y_train = math_data.create_training_data(\n",
        "        samples=500000, short_math=False)\n",
        "    math_model = create_load_model(model_file=model_file, start_fresh=False)\n",
        "    interrupted = math_train(math_model, x_train, Y_train, model_file=model_file, epochs=500, batch_size=20000)\n",
        "    math_data.check_results(math_model, samples=500, short_math=False)\n",
        "    if interrupted:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2WVhfsvuCCB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}