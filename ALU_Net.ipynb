{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALU_Net.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domschl/ALU_Net/blob/main/ALU_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XijwVpR4s0sQ"
      },
      "source": [
        "# A neural net that tries to become an ALU (arithmetic logic unit)\n",
        "\n",
        "This notebook can run\n",
        "\n",
        "- on local jupyter instances with a local graphics card\n",
        "- on Mac M1 with local jupyter instance and [Apple's tensorflow-plugin](https://developer.apple.com/metal/tensorflow-plugin/)\n",
        "- on Google Colab instances with either GPU or TPU runtime. The colab version uses a Google Drive account to cache data and model state within a Google Drive directory `My Drive/Colab Notebooks/ALU_Net`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0ui7VokTJqc"
      },
      "source": [
        "## 1. Configuration and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia2sNM2TTJqm"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import json\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "use_keras_project_versions=False\n",
        "# Namespaces, namespaces\n",
        "if use_keras_project_versions is False:\n",
        "    # print(\"Importing Keras from tensorflow project (it won't work otherwise with TPU)\")\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers, regularizers, callbacks, metrics, optimizers\n",
        "else:\n",
        "    # print(\"Importing Keras from keras project (which had recently declared independence [again]) -- as recommended\")\n",
        "    use_keras_project_versions=True\n",
        "    import keras\n",
        "    from keras import layers, regularizers, callbacks, metrics, optimizers\n",
        "\n",
        "try:\n",
        "    # Google Drive is used in Colab instances to save trained nets and tensorboard logs\n",
        "    from google.colab import drive\n",
        "    is_colab_init = True\n",
        "except:\n",
        "    is_colab_init = False\n",
        "    pass\n",
        "\n",
        "if is_colab_init is True:\n",
        "    # The following code loads the utility module ALU_Tools.py directly from github\n",
        "    # Into Google Colab (or other jupyter instances)\n",
        "    def import_from_github(fn, repo_link, force_github_update=False):\n",
        "        if os.path.exists(fn) is False or force_github_update is True:\n",
        "            print(f\"Loading {fn} module from github...\")\n",
        "            if os.path.exists(fn) is True:\n",
        "                !rm -v {fn}\n",
        "            !wget {repo_link}\n",
        "    force_github_update = True  # Note: Even if set to True, you still need to restart the runtime to get an updated version.\n",
        "    import_from_github('ml_env_tools.py','https://raw.githubusercontent.com/domschl/ALU_Net/main/ml_env_tools.py',force_github_update)\n",
        "    import_from_github('ml_tuner.py','https://raw.githubusercontent.com/domschl/ALU_Net/main/ml_tuner.py',force_github_update)\n",
        "    import_from_github('ALU_Dataset.py','https://raw.githubusercontent.com/domschl/ALU_Net/main/ALU_Dataset.py',force_github_update)\n",
        "\n",
        "from ml_env_tools import MLEnv\n",
        "from ml_tuner import MLTuner\n",
        "from ALU_Dataset import ALU_Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Ag-07-gmWM"
      },
      "source": [
        "def model_large(inputs, params):\n",
        "    # Input goes parallel into 3 streams which will be combined at the end:\n",
        "    # Stream 1: convolutions\n",
        "    d=[]\n",
        "    xs=[]\n",
        "    x=[]\n",
        "\n",
        "    shaper = layers.Reshape(target_shape=(36, 1,), input_shape=(36,))\n",
        "    x.append(shaper(inputs))  # x[0]\n",
        "\n",
        "    for layer in range(0, params[\"conv_layers\"]):\n",
        "        d.append(layers.Conv1D(filters=params[\"filters\"], kernel_size=params[\"kernel_size\"], strides=params[\"strides\"], padding=params[\"padding\"], kernel_regularizer=regularizers.l2(\n",
        "            params[\"regu1\"]), activation=\"relu\"))\n",
        "        x.append(d[layer](x[layer]))\n",
        "\n",
        "    flatter = layers.Flatten()\n",
        "    xf = flatter(x[-1])\n",
        "    de1 = layers.Dense(params[\"neurons\"], kernel_regularizer=regularizers.l2(\n",
        "        params[\"regu2\"]), activation=\"relu\")\n",
        "    xe1 = de1(xf)\n",
        "\n",
        "    # Use sigmoid to map to bits 0..1\n",
        "    de2 = layers.Dense(32, activation=\"sigmoid\")\n",
        "    outputs = de2(xe1)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fThFyT8DgmWN"
      },
      "source": [
        "def model_medium(inputs, params):\n",
        "    x=[]\n",
        "    d=[]\n",
        "    shaper = layers.Reshape(target_shape=(36, 1,), input_shape=(36,))\n",
        "    x.append(shaper(inputs))\n",
        "\n",
        "    for layer in range(0,params[\"lstm_layers\"]):\n",
        "        if layer<params[\"lstm_layers\"]-1:\n",
        "            d.append(layers.LSTM(params[\"lstm_neurons\"], return_sequences=True))\n",
        "        else:\n",
        "            d.append(layers.LSTM(params[\"lstm_neurons\"]))\n",
        "        x.append(d[layer](x[layer]))\n",
        "\n",
        "    # x3t = tf.transpose(x3,[0,2,1])\n",
        "\n",
        "    # flatter = layers.Flatten()\n",
        "    # xf = flatter(x[-1])\n",
        "\n",
        "    de1 = layers.Dense(params[\"neurons\"], kernel_regularizer=regularizers.l2(\n",
        "        params[\"regu1\"]), activation=\"relu\")\n",
        "    xe1 = de1(x[-1]) # xf)\n",
        "\n",
        "    de2 = layers.Dense(32, activation=\"sigmoid\")\n",
        "    outputs = de2(xe1)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltKUec3ahL8g"
      },
      "source": [
        "def model_minimal_prm(inputs, params):\n",
        "    df=[]\n",
        "    xf=[]\n",
        "    xfs=[]\n",
        "    dc=[]\n",
        "    df.append(layers.Dense(params[\"neurons\"], kernel_regularizer=regularizers.l2(\n",
        "        params[\"regu1\"]), activation=\"relu\"))\n",
        "    xf.append(df[0](inputs))\n",
        "\n",
        "    for layer in range(1,params[\"layer_cnt\"]):\n",
        "        df.append(layers.Dense(params[\"neurons\"], kernel_regularizer=regularizers.l2(\n",
        "            params[\"regu1\"]), activation=\"relu\"))\n",
        "        xfs.append(df[layer](xf[layer-1]))\n",
        "        dc.append(layers.Concatenate())\n",
        "        xf.append(dc[layer-1]([xfs[layer-1], xf[layer-1]]))\n",
        "    print(f\"len xf: {len(xf)}, {params['layer_cnt']}\")\n",
        "    de2 = layers.Dense(32, activation=\"sigmoid\")\n",
        "    outputs = de2(xf[params[\"layer_cnt\"]-1])\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn3rAlvqgmWO"
      },
      "source": [
        "def create_load_model(model_variant, params, save_path=None, import_weights=True):\n",
        "    \"\"\" Create or load a model \"\"\"\n",
        "    if save_path is None or not os.path.exists(save_path) or import_weights is False: #or is_tpu is True:\n",
        "        print(\"Initializing new model...\")\n",
        "        inputs = keras.Input(shape=(36,))  # depends on encoding of op-code!\n",
        "        if model_variant not in model_variants:\n",
        "            print('Unkown model type')\n",
        "            return None\n",
        "        outputs = model_variants[model_variant](inputs, params)\n",
        "        model = keras.Model(inputs=inputs, outputs=outputs, name=\"maths_\"+model_variant)\n",
        "        print(f\"Compiling new model of type {model_variant}\")\n",
        "        if use_keras_project_versions is False: \n",
        "            opti = keras.optimizers.Adam(learning_rate=params[\"learning_rate\"])\n",
        "        else:\n",
        "            opti = optimizers.Adam(learning_rate=params[\"learning_rate\"])\n",
        "        model.compile(loss=\"mean_squared_error\", optimizer=opti, metrics=[metrics.MeanSquaredError(), 'accuracy'])\n",
        "    else:\n",
        "        print(f\"Loading standard-format model of type {model_variant} from {model_path}\")\n",
        "        model = tf.keras.models.load_model(save_path)\n",
        "        print(\"Continuing training from existing model\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqxHzunzgmWP"
      },
      "source": [
        "def get_model(ml_env, model_variant, params, save_path=None, on_tpu=False, import_weights=False):\n",
        "    if on_tpu is True:\n",
        "        if ml_env.tpu_is_init is False:\n",
        "            cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=ml_env.tpu_address)\n",
        "            tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "            tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)    \n",
        "            ml_env.tpu_is_init=True\n",
        "        with tpu_strategy.scope():\n",
        "            print(\"Creating TPU-scope model\")\n",
        "            model = create_load_model(model_variant, params, save_path=save_path, import_weights=import_weights)\n",
        "        if import_weights is True and ml_env.weights_file is not None and os.path.exists(ml_env.weights_file):\n",
        "            print(\"Injecting saved weights into TPU model, loading...\")\n",
        "            temp_model = create_load_model(model_variant, params, save_path=save_path, import_weights=import_weights)\n",
        "            temp_model.load_weights(ml_env.weights_file)\n",
        "            print(\"Injecting...\")\n",
        "            model.set_weights(temp_model.get_weights())\n",
        "            print(\"Updated TPU weights from saved model\")\n",
        "        return model\n",
        "    else:\n",
        "        print(\"Creating standard-scope model\")\n",
        "        model = create_load_model(model_variant, params, save_path=save_path, import_weights=import_weights)\n",
        "        if import_weights is True and ml_env.weights_file is not None and os.path.exists(ml_env.weights_file):\n",
        "            print(\"Injecting saved weights into model, loading...\")        \n",
        "            model.load_weights(ml_env.weights_file)\n",
        "            imported_weights_file = ml_env.weights_file+'-imported'\n",
        "            os.rename(ml_env.weights_file, imported_weights_file)\n",
        "            print(f\"Renamed weights file {ml_env.weights_file} to {imported_weights_file} to prevent further imports!\")\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HDT65wgmWP"
      },
      "source": [
        "def math_train(mlenv:MLEnv, model, dataset, validation, batch_size=8192, epochs=5000, steps_per_epoch=2000, log_path=\"./logs\"):\n",
        "    \"\"\" Training loop \"\"\"\n",
        "    interrupted = 2\n",
        "    hist = None\n",
        "    tensorboard_callback = callbacks.TensorBoard(\n",
        "        log_dir=log_path\n",
        "        # histogram_freq=1\n",
        "        # update_freq='batch'\n",
        "        )\n",
        "    if mlenv.is_tpu is False: # TPUs update Tensorboard too asynchronously, data is corrupted by updates during mirroring.\n",
        "        lambda_callback = tf.keras.callbacks.LambdaCallback(\n",
        "            on_epoch_end = ml_env.epoch_time_func\n",
        "        )\n",
        "    try:\n",
        "        if ml_env.is_tpu:\n",
        "            hist = model.fit(dataset, validation_data=validation, epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1, callbacks=[tensorboard_callback])\n",
        "            interrupted=0\n",
        "        else:\n",
        "            hist = model.fit(dataset, validation_data=validation, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[tensorboard_callback, lambda_callback])\n",
        "            interrupted=0\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\")\n",
        "        print(\"\")\n",
        "        print(\"---------INTERRUPT----------\")\n",
        "        print(\"\")\n",
        "        print(\"Training interrupted\")\n",
        "        interrupted = 1 # user stopped runtime\n",
        "    except Exception as e:\n",
        "        interruped = 2  # Bad: something crashed.\n",
        "        print(f\"INTERNAL ERROR\")\n",
        "        print(f\"Exception {e}\")\n",
        "    finally:\n",
        "        return interrupted, hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9_Ey8nDgmWP"
      },
      "source": [
        "def instantiate_models(ml_env:MLEnv, model_variant, params, save_path=None, import_weights=True):\n",
        "    if ml_env.is_tpu:\n",
        "        # Generate a second CPU model for testing:\n",
        "        test_model = get_model(ml_env, model_variant, params, save_path=save_path, on_tpu=False, import_weights=import_weights)\n",
        "        math_model = get_model(ml_env, model_variant, params, save_path=save_path, on_tpu=True, import_weights=import_weights)\n",
        "    else:\n",
        "        test_model = None\n",
        "        math_model = get_model(ml_env, model_variant, params, save_path=save_path, on_tpu=False, import_weights=import_weights)\n",
        "    return math_model, test_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL4L7FZYgmWP"
      },
      "source": [
        "def do_training(mlenv:MLEnv, math_model, training_dataset, validation_dataset, math_data, epochs_per_cycle, model_path=None, \n",
        "                weights_file=None, test_model=None, cycles=100, steps_per_epoch=1000, reweight_size=1000, valid_ops=None, regenerate_data_after_cycles=0, data_func=None,\n",
        "                log_path='./logs'):\n",
        "    # Training\n",
        "    for mep in range(0, cycles):\n",
        "        print()\n",
        "        print()\n",
        "        print(f\"------ Meta-Epoch {mep+1}/{cycles} ------\")\n",
        "        print()\n",
        "        if regenerate_data_after_cycles!=0 and data_func is not None:\n",
        "            if mep>0 and (mep+1)%regenerate_data_after_cycles==0:\n",
        "                training_dataset, validation_dataset = data_func()\n",
        "        if mep==0 and ml_env.is_tpu is True:\n",
        "            print(\"There will be some warnings by Tensorflow, documenting some state of internal decoherence, currently they can be ignored.\")\n",
        "        interrupted, hist = math_train(ml_env, math_model, training_dataset, validation=validation_dataset, epochs=epochs_per_cycle, steps_per_epoch=steps_per_epoch, log_path=log_path)\n",
        "        if interrupted <2:\n",
        "            if ml_env.is_tpu:\n",
        "                mlenv.gdrive_log_mirror()  # TPUs can only savely mirror Tensorboard data once training is finished for an meta-epoch.\n",
        "                if test_model is None:\n",
        "                    print(\"Fatal: tpu-mode needs test_model on CPU\")\n",
        "                    return False\n",
        "                print(\"Injecting weights into test_model:\")\n",
        "                test_model.set_weights(math_model.get_weights())\n",
        "                if weights_file is not None:\n",
        "                    print(f\"Saving test-model weights to {weights_file}\")\n",
        "                    test_model.save_weights(weights_file)\n",
        "                    print(\"Done\")\n",
        "                print(f\"Checking {reweight_size} datapoints for accuracy...\")\n",
        "                math_data.check_results(test_model, samples=reweight_size, short_math=False, valid_ops=valid_ops, verbose=False)\n",
        "            else:\n",
        "                if model_path is not None:\n",
        "                    print(\"Saving math-model\")\n",
        "                    math_model.save(model_path)\n",
        "                    print(\"Done\")\n",
        "                print(f\"Checking {reweight_size} datapoints for accuracy...\")\n",
        "                math_data.check_results(math_model, samples=reweight_size, short_math=False, valid_ops=valid_ops, verbose=False)\n",
        "        if interrupted>0:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yjwuceDgmWQ"
      },
      "source": [
        "model_variants = {\"large\": model_large,\n",
        "                  \"medium\": model_medium,\n",
        "                  \"minimal_prm\": model_minimal_prm\n",
        "                  }\n",
        "\n",
        "model_variant = 'medium'  # see: model_variants definition.\n",
        "epochs_per_cycle = 250\n",
        "cycles = 10  # perform 100 cycles, each cycle trains with epochs_per_cycle epochs.\n",
        "regenerate_data_after_cycles = 3  # if !=0, the training data will be created anew after each number of \n",
        "                                  # regenerace_data_after_cycles cycles. Disadvantage: when training TPU, \n",
        "                                  # Google might use the time it takes to regenerate to training data to \n",
        "                                  # terminate your session :-/\n",
        "samples = 2000000  # Number training data examples\n",
        "batch_size = 20000\n",
        "learning_rate = 0.001\n",
        "import_weights=True\n",
        "valid_ops = None  # Default: None (all ops), or list of ops, e.g. ['*', '/'] trains only multiplication and division.\n",
        "steps_per_epoch = samples // batch_size  # TPU stuff\n",
        "\n",
        "params_large={\n",
        "    \"conv_layers\": 4,\n",
        "    \"filters\":64,\n",
        "    \"kernel_size\": 3,\n",
        "    \"strides\": 1,\n",
        "    \"padding\": \"same\",\n",
        "    \"neurons\": 128,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"regu1\": 1e-8,\n",
        "    \"regu2\": 1e-8\n",
        "}\n",
        "\n",
        "# params_medium = {'lstm_layers': 4, 'lstm_neurons': 704, 'neurons': 368, 'learning_rate': 0.0014, 'regu1': 2e-07}  # with full history\n",
        "params_medium = {'learning_rate': 0.0012, 'lstm_layers': 5, 'lstm_neurons': 640, 'neurons': 368, 'regu1': 8e-07}      # (with final layer not giving full history)\n",
        "\n",
        "params_minimal_prm={\n",
        "    \"layer_cnt\": 8,\n",
        "    \"neurons\":512, \n",
        "    \"learning_rate\": 0.001,\n",
        "    \"regu1\": 1e-8\n",
        "}\n",
        "\n",
        "params=params_medium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnBLx9GwgmWQ"
      },
      "source": [
        "ml_env=MLEnv()\n",
        "math_data=ALU_Dataset(ml_env)\n",
        "\n",
        "root_path, project_path, model_path, weights_file, cache_path, log_path = ml_env.init_paths(\"ALU_Net\", \"math_model\", model_variant=model_variant, log_to_gdrive=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iliMhQoN2UU"
      },
      "source": [
        "apply_model_tuner = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7ZPfXQdPe-d"
      },
      "source": [
        "if apply_model_tuner is True:\n",
        "    as_train, as_val = math_data.get_datasets(samples=100000, validation_samples=10000, cache_path=cache_path)\n",
        "\n",
        "    def tuner_eval(ml_env:MLEnv, model_variant, params, batch_size, epochs):\n",
        "        math_model, _ = instantiate_models(ml_env, model_variant, params, save_path=None, import_weights=False)\n",
        "        interrupted, hist = math_train(ml_env, math_model, as_train, as_val, batch_size=batch_size, epochs=epochs)\n",
        "        print(params, end=\" [ \")\n",
        "        ev = 1/hist.history['val_loss'][-1]+hist.history['val_accuracy'][-1]*50\n",
        "        return ev\n",
        "\n",
        "    tuner_eval_func = lambda params : tuner_eval(ml_env, model_variant, params, batch_size=1024, epochs=15)\n",
        "    ml_tuner = MLTuner(ml_env, model_variant)\n",
        "\n",
        "    # ev=41.651991886632274: {'lstm_layers': 5, 'lstm_neurons': 640, 'neurons': 368, 'learning_rate': 0.0014, 'regu1': 8e-07}\n",
        "    param_space = {\n",
        "            \"lstm_layers\": [3,4,5],\n",
        "            \"lstm_neurons\": [640, 704, 768],\n",
        "            \"neurons\": [368, 432, 512],\n",
        "            \"learning_rate\": [0.0014, 0.0012, 0.0016],\n",
        "            \"regu1\": [8e-7, 2e-7, 1e-7, 8e-8]\n",
        "        }\n",
        "\n",
        "    best_params = ml_tuner.tune(param_space, tuner_eval_func)\n",
        "    params = best_params\n",
        "    import_weights=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCOAdbtPfQki"
      },
      "source": [
        "params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wN1G_qPgmWQ"
      },
      "source": [
        "create_train_val_data = lambda regen : math_data.get_datasets(pre_weight=True, samples=samples, validation_samples=50000, batch_size=batch_size, short_math=False, \n",
        "                                     valid_ops=valid_ops, cache_path=cache_path, use_cache=True, regenerate_cached_data=regen)\n",
        "create_train_val_data_regen = lambda : create_train_val_data(True)\n",
        "train, val = create_train_val_data(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSL6lysogmWQ"
      },
      "source": [
        "math_model, test_model = instantiate_models(ml_env, model_variant, params, save_path=model_path, import_weights=import_weights)\n",
        "# math_model, test_model = instantiate_models(ml_env, model_variant, params, save_path=None, import_weights=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epfwj4czgmWQ"
      },
      "source": [
        "try:\n",
        "    # use the python variable log_path:\n",
        "    get_ipython().run_line_magic('tensorboard', '--logdir \"{log_path}\"')\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntW3khTWgmWQ"
      },
      "source": [
        "do_training(ml_env, math_model, train, val, math_data, epochs_per_cycle, model_path=model_path, \n",
        "            weights_file=weights_file, test_model=test_model, cycles=cycles, steps_per_epoch=steps_per_epoch, valid_ops=valid_ops, \n",
        "            regenerate_data_after_cycles=regenerate_data_after_cycles, data_func=create_train_val_data_regen, log_path=log_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6dRCu6TJqm"
      },
      "source": [
        "# Testing and applying the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hcGr9h_p9_R",
        "tags": []
      },
      "source": [
        "if ml_env.is_tpu is False:\n",
        "    test_model = math_model\n",
        "math_data.check_results(test_model, samples=100, short_math=False, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8ZRa8GpThA"
      },
      "source": [
        "dx,dy,_,_,_=math_data.create_data_point(22,33,'+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZt0CbNdqpqW"
      },
      "source": [
        "math_data.decode_results(test_model.predict(np.array([dx])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV52DL3gq0rI"
      },
      "source": [
        "def calc(inp):\n",
        "    args=inp.split(' ')\n",
        "    if len(args)!=3:\n",
        "        print(\"need three space separated tokens: <int> <operator> <int>, e.g. '3 + 4' or '4 XOR 5'\")\n",
        "        return False\n",
        "    if args[1] not in math_data.model_ops:\n",
        "        print(f\"{args[1]} is not a known operator.\")\n",
        "        return False\n",
        "    op1=int(args[0])\n",
        "    op2=int(args[2])\n",
        "    dx,dy,_,_,_=math_data.create_data_point(op1, op2, args[1])\n",
        "    ans=math_data.decode_results(test_model.predict(np.array([dx])))\n",
        "    print(f\"{op1} {args[1]} {op2} = {ans[0]}\")\n",
        "    op=f\"{op1} {args[1]} {op2}\"\n",
        "    op=op.replace('AND', '&').replace('XOR','^').replace('=','==').replace('OR','|')\n",
        "    an2=eval(op)\n",
        "    if ans[0]!=an2:\n",
        "        print(\"Error\")\n",
        "        print(bin(ans[0]))\n",
        "        print(bin(an2))\n",
        "    return ans[0],an2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeqeW9hlrEEE"
      },
      "source": [
        "calc(\"222 = 223\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0jjSQodrH0s"
      },
      "source": [
        "calc(\"8812 = 8812\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoK-LUr-s9IO"
      },
      "source": [
        "calc(\"3 * 4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frQNAv4Fs-_w"
      },
      "source": [
        "calc (\"1 AND 3\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}