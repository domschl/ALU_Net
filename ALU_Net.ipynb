{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/domschl/ALU_Net/blob/main/ALU_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XijwVpR4s0sQ"
   },
   "source": [
    "# Simulating an ALU (arithmetic logic unit) with a neural network\n",
    "\n",
    "The neural network is trained to perform the operations `+`, `-`, `*`, `/`, `%`, `AND`, `OR`, `XOR`, `>`, `<`, `=`, `!=` on two unsigned integers and return the result.\n",
    "\n",
    "## This notebook can run\n",
    "\n",
    "- on local jupyter instances with a local graphics card\n",
    "- on Mac M1 with local jupyter instance and [Apple's tensorflow-plugin](https://developer.apple.com/metal/tensorflow-plugin/)\n",
    "- on Google Colab instances with either GPU or TPU runtime. The colab version uses a Google Drive account to cache data and model state within a Google Drive directory `My Drive/Colab Notebooks/ALU_Net`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0ui7VokTJqc"
   },
   "source": [
    "## 1. Configuration and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ia2sNM2TTJqm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "use_keras_project_versions=False\n",
    "# Namespaces, namespaces\n",
    "if use_keras_project_versions is False:\n",
    "    # print(\"Importing Keras from tensorflow project (it won't work otherwise with TPU)\")\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers, regularizers, callbacks, metrics, optimizers\n",
    "else:\n",
    "    # print(\"Importing Keras from keras project (which had recently declared independence [again]) -- as recommended\")\n",
    "    use_keras_project_versions=True\n",
    "    import keras\n",
    "    from keras import layers, regularizers, callbacks, metrics, optimizers\n",
    "\n",
    "try:\n",
    "    # Google Drive is used in Colab instances to save trained nets and tensorboard logs\n",
    "    from google.colab import drive\n",
    "    is_colab_init = True\n",
    "except:\n",
    "    is_colab_init = False\n",
    "    pass\n",
    "\n",
    "if is_colab_init is True:\n",
    "    # The following code loads the utility modules directly from github\n",
    "    # Into Google Colab (or other jupyter instances)\n",
    "    # WARNING: indeterministic caching by infrastructure: it might take some\n",
    "    # minutes until a change in github is actually accessible in colab (aggressive caching). Sometimes\n",
    "    # it's necessary to factory reset the runtime, and even that gets ignoredd from time to time.\n",
    "    def import_from_github(fn, repo_root_link, force_github_update=False):\n",
    "        if os.path.exists(fn) is False or force_github_update is True:\n",
    "            repo_link=repo_root_link+fn\n",
    "            print(f\"Loading {fn} module from github at {repo_link}...\")\n",
    "            if os.path.exists(fn) is True:\n",
    "                !rm -v {fn}\n",
    "            !wget -nv --show-progress {repo_link}\n",
    "    force_github_update = True  # Note: Even if set to True, you still need to restart the runtime to get an updated version.\n",
    "    repo_root_link = 'https://raw.githubusercontent.com/domschl/ALU_Net/main/'\n",
    "    import_from_github('ml_env_tools.py', repo_root_link, force_github_update)\n",
    "    import_from_github('ml_tuner.py', repo_root_link, force_github_update)\n",
    "    import_from_github('ALU_Dataset.py', repo_root_link, force_github_update)\n",
    "    import_from_github('keras_custom_layers.py', repo_root_link, force_github_update)\n",
    "\n",
    "from ml_env_tools import MLEnv\n",
    "from ml_tuner import MLTuner\n",
    "from ALU_Dataset import ALU_Dataset\n",
    "from keras_custom_layers import ResidualBlock, ResidualDense, ResidualDenseStack, ParallelResidualDenseStacks, SelfAttention, MultiHeadSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hZ_tOVlPdamx"
   },
   "outputs": [],
   "source": [
    "def model_res_mod(inputs, params):\n",
    "    # see: keras_custom_layers.py for layer definition:\n",
    "    x=inputs\n",
    "    print(f\"input-shape: {x.shape}\")\n",
    "    self_att=[]\n",
    "    for _ in range(0, params['self_attention_layers']):\n",
    "        self_att.append(MultiHeadSelfAttention(params['self_attention_heads'], units=params['self_attention_units']))\n",
    "    for i in range(0, params['self_attention_layers']):\n",
    "        x=self_att[i](x)+x\n",
    "    fl = layers.Flatten()\n",
    "    print(f\"x.shape bef. fl: {x.shape}\")\n",
    "    x = fl(x)\n",
    "    print(f\"x.shape after. fl: {x.shape}\")\n",
    "    scale = layers.Dense(params['units'], activation=None)\n",
    "    x=scale(x)\n",
    "    prds = ResidualDenseStack(params[\"units\"], params[\"layers\"], regularizer=params[\"regularizer\"])\n",
    "    x=prds(x)\n",
    "    rescale = layers.Dense(params['output_size'], activation=\"sigmoid\")\n",
    "    outputs = rescale(x)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xn3rAlvqgmWO"
   },
   "outputs": [],
   "source": [
    "def create_load_model(ml_env:MLEnv, model_variant, params, save_path=None, import_weights=True):\n",
    "    \"\"\" Create or load a model \"\"\"\n",
    "    if save_path is None or not os.path.exists(save_path) or import_weights is False: #or is_tpu is True:\n",
    "        print(\"Initializing new model...\")\n",
    "        # inputs = keras.Input(shape=(params['input_size'],))  # depends on encoding of op-code!\n",
    "        inputs = keras.Input(shape=params['input_size'])  # depends on encoding of op-code!\n",
    "        if model_variant not in model_variants:\n",
    "            print('Unkown model type')\n",
    "            return None\n",
    "        outputs = model_variants[model_variant](inputs, params)\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs, name=\"maths_\"+model_variant)\n",
    "        print(f\"Compiling new model of type {model_variant}\")\n",
    "        if use_keras_project_versions is False: \n",
    "            opti = keras.optimizers.Adam(learning_rate=params[\"learning_rate\"])\n",
    "        else:\n",
    "            opti = optimizers.Adam(learning_rate=params[\"learning_rate\"])\n",
    "        if ml_env.is_tpu:\n",
    "            # use steps_per_execution magic (or not)\n",
    "            # model.compile(loss=\"mean_squared_error\", optimizer=opti, steps_per_execution=50, metrics=[metrics.MeanSquaredError(), 'accuracy'])\n",
    "            model.compile(loss=\"mean_squared_error\", optimizer=opti, metrics=[metrics.MeanSquaredError(), 'accuracy'])\n",
    "        else:\n",
    "            model.compile(loss=\"mean_squared_error\", optimizer=opti, metrics=[metrics.MeanSquaredError(), 'accuracy'])\n",
    "    else:\n",
    "        print(f\"Loading standard-format model of type {model_variant} from {model_path}\")\n",
    "        model = tf.keras.models.load_model(save_path)\n",
    "        print(\"Continuing training from existing model\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iqxHzunzgmWP"
   },
   "outputs": [],
   "source": [
    "def get_model(ml_env, model_variant, params, save_path=None, on_tpu=False, import_weights=False):\n",
    "    if on_tpu is True:\n",
    "        if ml_env.tpu_is_init is False:\n",
    "            cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=ml_env.tpu_address)\n",
    "            tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "            tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)    \n",
    "            ml_env.tpu_is_init=True\n",
    "        with tpu_strategy.scope():\n",
    "            print(\"Creating TPU-scope model\")\n",
    "            model = create_load_model(ml_env, model_variant, params, save_path=save_path, import_weights=import_weights)\n",
    "        if import_weights is True and ml_env.weights_file is not None and os.path.exists(ml_env.weights_file):\n",
    "            print(\"Injecting saved weights into TPU model, loading...\")\n",
    "            temp_model = create_load_model(ml_env, model_variant, params, save_path=save_path, import_weights=import_weights)\n",
    "            temp_model.load_weights(ml_env.weights_file)\n",
    "            print(\"Injecting...\")\n",
    "            model.set_weights(temp_model.get_weights())\n",
    "            print(\"Updated TPU weights from saved model\")\n",
    "        return model\n",
    "    else:\n",
    "        print(\"Creating standard-scope model\")\n",
    "        model = create_load_model(ml_env, model_variant, params, save_path=save_path, import_weights=import_weights)\n",
    "        if import_weights is True and ml_env.weights_file is not None and os.path.exists(ml_env.weights_file):\n",
    "            print(\"Injecting saved weights into model, loading...\")        \n",
    "            model.load_weights(ml_env.weights_file)\n",
    "            imported_weights_file = ml_env.weights_file+'-imported'\n",
    "            os.rename(ml_env.weights_file, imported_weights_file)\n",
    "            print(f\"Renamed weights file {ml_env.weights_file} to {imported_weights_file} to prevent further imports!\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y4HDT65wgmWP"
   },
   "outputs": [],
   "source": [
    "def math_train(mlenv:MLEnv, model, dataset, validation, batch_size=8192, epochs=5000, steps_per_epoch=2000, log_path=\"./logs\"):\n",
    "    \"\"\" Training loop \"\"\"\n",
    "    interrupted = 2\n",
    "    hist = None\n",
    "    tensorboard_callback = callbacks.TensorBoard(\n",
    "        log_dir=log_path\n",
    "        # histogram_freq=1\n",
    "        # update_freq='batch'\n",
    "        )\n",
    "    if mlenv.is_tpu is False: # TPUs update Tensorboard too asynchronously, data is corrupted by updates during mirroring.\n",
    "        lambda_callback = tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end = ml_env.epoch_time_func\n",
    "        )\n",
    "    try:\n",
    "        if ml_env.is_tpu:\n",
    "            if use_validation_with_tpu is True:\n",
    "                hist = model.fit(dataset, validation_data=validation, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=1, callbacks=[tensorboard_callback])\n",
    "            else:\n",
    "                hist = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1, callbacks=[tensorboard_callback])\n",
    "            interrupted=0\n",
    "        else:\n",
    "            hist = model.fit(dataset, validation_data=validation, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[tensorboard_callback, lambda_callback])\n",
    "            interrupted=0\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"---------INTERRUPT----------\")\n",
    "        print(\"\")\n",
    "        print(\"Training interrupted\")\n",
    "        interrupted = 1 # user stopped runtime\n",
    "    except Exception as e:\n",
    "        interruped = 2  # Bad: something crashed.\n",
    "        print(f\"INTERNAL ERROR\")\n",
    "        print(f\"Exception {e}\")\n",
    "    finally:\n",
    "        return interrupted, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z9_Ey8nDgmWP"
   },
   "outputs": [],
   "source": [
    "def instantiate_models(ml_env:MLEnv, model_variant, params, save_path=None, import_weights=True):\n",
    "    if ml_env.is_tpu:\n",
    "        # Generate a second CPU model for testing:\n",
    "        math_model = get_model(ml_env, model_variant, params, save_path=save_path, on_tpu=True, import_weights=import_weights)\n",
    "        test_model = get_model(ml_env, model_variant, params, save_path=save_path, on_tpu=False, import_weights=import_weights)\n",
    "    else:\n",
    "        test_model = None\n",
    "        math_model = get_model(ml_env, model_variant, params, save_path=save_path, on_tpu=False, import_weights=import_weights)\n",
    "    return math_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hL4L7FZYgmWP"
   },
   "outputs": [],
   "source": [
    "def do_training(mlenv:MLEnv, math_model, training_dataset, validation_dataset, math_data, epochs_per_cycle, model_path=None, \n",
    "                weights_file=None, test_model=None, cycles=100, steps_per_epoch=1000, reweight_size=1000, valid_ops=None, regenerate_data_after_cycles=0, data_func=None,\n",
    "                log_path='./logs'):\n",
    "    # Training\n",
    "    for mep in range(0, cycles):\n",
    "        print()\n",
    "        print()\n",
    "        print(f\"------ Meta-Epoch {mep+1}/{cycles} ------\")\n",
    "        print()\n",
    "        if regenerate_data_after_cycles!=0 and data_func is not None:\n",
    "            if mep>0 and (mep+1)%regenerate_data_after_cycles==0:\n",
    "                training_dataset, validation_dataset = data_func()\n",
    "        if mep==0 and ml_env.is_tpu is True:\n",
    "            print(\"There will be some warnings by Tensorflow, documenting some state of internal decoherence, currently they can be ignored.\")\n",
    "        interrupted, hist = math_train(ml_env, math_model, training_dataset, validation=validation_dataset, epochs=epochs_per_cycle, steps_per_epoch=steps_per_epoch, log_path=log_path)\n",
    "        if interrupted <2:\n",
    "            if ml_env.is_tpu:\n",
    "                mlenv.gdrive_log_mirror()  # TPUs can only savely mirror Tensorboard data once training is finished for an meta-epoch.\n",
    "                if test_model is None:\n",
    "                    print(\"Fatal: tpu-mode needs test_model on CPU\")\n",
    "                    return False\n",
    "                print(\"Injecting weights into test_model:\")\n",
    "                test_model.set_weights(math_model.get_weights())\n",
    "                if weights_file is not None:\n",
    "                    print(f\"Saving test-model weights to {weights_file}\")\n",
    "                    test_model.save_weights(weights_file)\n",
    "                    print(\"Done\")\n",
    "                print(f\"Checking {reweight_size} datapoints for accuracy...\")\n",
    "                math_data.check_results(test_model, samples=reweight_size, vector=vector, valid_ops=valid_ops, verbose=False)\n",
    "            else:\n",
    "                if model_path is not None:\n",
    "                    print(\"Saving math-model\")\n",
    "                    math_model.save(model_path)\n",
    "                    print(\"Done\")\n",
    "                print(f\"Checking {reweight_size} datapoints for accuracy...\")\n",
    "                math_data.check_results(math_model, samples=reweight_size, vector=vector, valid_ops=valid_ops, verbose=False)\n",
    "        if interrupted>0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4b07h1AVAmtI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')] {}\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] {'device_name': 'METAL'}\n",
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "ml_env=MLEnv()\n",
    "bit_count = 15\n",
    "math_data=ALU_Dataset(ml_env, bit_count = bit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9yjwuceDgmWQ"
   },
   "outputs": [],
   "source": [
    "model_variants = {\"res_mod\": model_res_mod,\n",
    "                  }\n",
    "\n",
    "model_variant = 'res_mod'  # see: model_variants definition.\n",
    "epochs_per_cycle = 100\n",
    "cycles = 100  # perform 100 (meta-)cycles, each cycle trains with epochs_per_cycle epochs.\n",
    "regenerate_data_after_cycles = 0  # if !=0, the training data will be created anew after each number of \n",
    "                                  # regenerace_data_after_cycles cycles. Disadvantage: when training TPU, \n",
    "                                  # Google might use the time it takes to regenerate to training data to \n",
    "                                  # terminate your session :-/\n",
    "low_resource = True\n",
    "\n",
    "if low_resource is True:\n",
    "    samples = 100000  # Number training data examples. \n",
    "                    # WARNING: TPU simply crashes, if 2GB limit for entire set is reached.\n",
    "                    # Possible solutions: https://www.tensorflow.org/api_docs/python/tf/data/experimental/service#running_the_tfdata_service,\n",
    "                    # https://www.tensorflow.org/api_docs/python/tf/data/experimental/service , https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_input_pipeline.py#L33\n",
    "    validation_samples=10000\n",
    "else:\n",
    "    samples = 4000000  # Number training data examples. \n",
    "                    # WARNING: TPU simply crashes, if 2GB limit for entire set is reached.\n",
    "                    # Possible solutions: https://www.tensorflow.org/api_docs/python/tf/data/experimental/service#running_the_tfdata_service,\n",
    "                    # https://www.tensorflow.org/api_docs/python/tf/data/experimental/service , https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_input_pipeline.py#L33\n",
    "    validation_samples=100000\n",
    "    \n",
    "if low_resource is True:\n",
    "    batch_size = 2000\n",
    "else:\n",
    "    batch_size = 20000\n",
    "import_weights=True\n",
    "if import_weights is False:\n",
    "    print(\"WARNING: import weights is set to False!\")\n",
    "valid_ops = None  # Default: None (all ops), or list of ops, e.g. ['*', '/'] trains only multiplication and division.\n",
    "# valid_ops = ['*','/','+','-']\n",
    "# valid_ops = ['*']\n",
    "steps_per_epoch = samples // batch_size  # TPU stuff\n",
    "validation_steps= validation_samples // batch_size  # again TPU only\n",
    "use_validation_with_tpu = False  # Is somehow really, really slow\n",
    "\n",
    "params_res_mod={\n",
    "    \"self_attention_layers\": 4,\n",
    "    \"self_attention_heads\": 4,\n",
    "    \"self_attention_units\": 64,\n",
    "    \"units\": 64,\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"layers\": 1,\n",
    "    \"regularizer\": 1e-9\n",
    "    }\n",
    "\n",
    "params=params_res_mod\n",
    "vector = True\n",
    "\n",
    "if vector is True:\n",
    "    params['input_size'] = [3, math_data.embedding_size]\n",
    "else:\n",
    "    params['input_size'] = math_data.input_size\n",
    "params['output_size'] = math_data.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tnBLx9GwgmWQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root path: .\n",
      "Model save-path: ./math_model_res_mod\n",
      "Data cache path ./data\n"
     ]
    }
   ],
   "source": [
    "root_path, project_path, model_path, weights_file, cache_path, log_path = ml_env.init_paths(\"ALU_Net\", \"math_model\", model_variant=model_variant, log_to_gdrive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9iliMhQoN2UU"
   },
   "outputs": [],
   "source": [
    "apply_model_tuner = False   # Use GPU (not TPU!) for model_tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "r7ZPfXQdPe-d"
   },
   "outputs": [],
   "source": [
    "if apply_model_tuner is True:\n",
    "    as_train, as_val = math_data.get_datasets(samples=500000, validation_samples=50000, vector=vector, cache_path=cache_path)\n",
    "\n",
    "    def tuner_eval(ml_env:MLEnv, model_variant, params, batch_size, epochs):\n",
    "        math_model, _ = instantiate_models(ml_env, model_variant, params, save_path=None, import_weights=False)\n",
    "        interrupted, hist = math_train(ml_env, math_model, as_train, as_val, batch_size=batch_size, epochs=epochs)\n",
    "        print(params, end=\" [ \")\n",
    "        res = math_data.check_results(math_model, samples=100, valid_ops=valid_ops, verbose=False)\n",
    "        ev = 1/hist.history['val_loss'][-1]+hist.history['val_accuracy'][-1]*20\n",
    "        if res>0:\n",
    "            print(\"Success-rate: {res}\")\n",
    "            ev += res*5000\n",
    "        return ev\n",
    "\n",
    "    tuner_eval_func = lambda params : tuner_eval(ml_env, model_variant, params, batch_size=batch_size, epochs=20)\n",
    "    ml_tuner = MLTuner(ml_env, model_variant)\n",
    "\n",
    "    param_space_minimal_prm={\n",
    "    \"dense_layers\": [4,8,12],\n",
    "    \"dense_neurons\":[256,512,768], \n",
    "    \"learning_rate\": [0.001,0.002],\n",
    "    \"regu1\": [1e-8,1e-7]\n",
    "    }\n",
    "\n",
    "    best_params = ml_tuner.tune(param_space_minimal_prm, tuner_eval_func)\n",
    "    params = best_params\n",
    "    import_weights=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GCOAdbtPfQki"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attention_layers': 4,\n",
       " 'self_attention_heads': 4,\n",
       " 'self_attention_units': 64,\n",
       " 'units': 64,\n",
       " 'learning_rate': 0.002,\n",
       " 'layers': 1,\n",
       " 'regularizer': 1e-09,\n",
       " 'input_size': [3, 16],\n",
       " 'output_size': 32}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2wN1G_qPgmWQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data train loaded from cache\n",
      "Metal device set to: Apple M1\n",
      "Data validation loaded from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 07:58:15.091083: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-07 07:58:15.091188: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "create_train_val_data = lambda regen : math_data.get_datasets(pre_weight=False, samples=samples, validation_samples=validation_samples, batch_size=batch_size, \n",
    "                                     vector=vector, valid_ops=valid_ops, cache_path=cache_path, use_cache=True, regenerate_cached_data=regen)\n",
    "create_train_val_data_regen = lambda : create_train_val_data(True)\n",
    "train, val = create_train_val_data(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mbZ_R7anJRda"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_datasets\n",
    "# import tensorflow_datasets as tdfs\n",
    "# sa=SelfAttention()\n",
    "# nval=tdfs.as_numpy(val)\n",
    "# for n in nval:\n",
    "#     print(n[0].shape)   \n",
    "#     print(sa(n[0]).shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iSL6lysogmWQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating standard-scope model\n",
      "Initializing new model...\n",
      "input-shape: (None, 3, 16)\n",
      "x.shape bef. fl: (None, 3, 16)\n",
      "x.shape after. fl: (None, 48)\n",
      "Compiling new model of type res_mod\n",
      "Model: \"maths_res_mod\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 16)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_self_attention (Mult (None, 3, 16)        3172        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 3, 16)        0           multi_head_self_attention[0][0]  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_self_attention_1 (Mu (None, 3, 16)        3172        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 3, 16)        0           multi_head_self_attention_1[0][0]\n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_self_attention_2 (Mu (None, 3, 16)        3172        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 3, 16)        0           multi_head_self_attention_2[0][0]\n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_self_attention_3 (Mu (None, 3, 16)        3172        tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 3, 16)        0           multi_head_self_attention_3[0][0]\n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 48)           0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           3136        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "residual_dense_stack (ResidualD (None, 64)           4416        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        residual_dense_stack[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 22,320\n",
      "Trainable params: 22,192\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "math_model, test_model = instantiate_models(ml_env, model_variant, params, save_path=model_path, import_weights=import_weights)\n",
    "# math_model, test_model = instantiate_models(ml_env, model_variant, params, save_path=None, import_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Epfwj4czgmWQ"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # use the python variable log_path:\n",
    "    get_ipython().run_line_magic('tensorboard', '--logdir \"{log_path}\"')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ntW3khTWgmWQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------ Meta-Epoch 1/100 ------\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 07:58:15.530261: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-07 07:58:15.530273: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-12-07 07:58:15.530447: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-07 07:58:16.785490: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-07 07:58:16.795829: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-07 07:58:16.796207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/50 [..............................] - ETA: 1:48 - loss: 0.3196 - mean_squared_error: 0.3196 - accuracy: 0.0390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 07:58:17.832158: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-12-07 07:58:17.832170: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/50 [>.............................] - ETA: 14s - loss: 0.3118 - mean_squared_error: 0.3118 - accuracy: 0.0383 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 07:58:18.081128: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-07 07:58:18.104279: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-12-07 07:58:18.123342: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/train/plugins/profile/2021_12_07_07_58_18\n",
      "\n",
      "2021-12-07 07:58:18.139985: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.trace.json.gz\n",
      "2021-12-07 07:58:18.145285: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/train/plugins/profile/2021_12_07_07_58_18\n",
      "\n",
      "2021-12-07 07:58:18.145489: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.memory_profile.json.gz\n",
      "2021-12-07 07:58:18.146457: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_12_07_07_58_18\n",
      "Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_12_07_07_58_18/m1air.fritz.box.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 0.1350 - mean_squared_error: 0.1350 - accuracy: 0.1059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 07:58:30.312034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 15s 266ms/step - loss: 0.1350 - mean_squared_error: 0.1350 - accuracy: 0.1059 - val_loss: 0.0958 - val_mean_squared_error: 0.0958 - val_accuracy: 0.1962\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0746 - mean_squared_error: 0.0746 - accuracy: 0.1709 - val_loss: 0.0761 - val_mean_squared_error: 0.0761 - val_accuracy: 0.0813\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0676 - mean_squared_error: 0.0676 - accuracy: 0.2031 - val_loss: 0.0780 - val_mean_squared_error: 0.0780 - val_accuracy: 0.1098\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0642 - mean_squared_error: 0.0642 - accuracy: 0.2310 - val_loss: 0.0663 - val_mean_squared_error: 0.0663 - val_accuracy: 0.1227\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0609 - mean_squared_error: 0.0609 - accuracy: 0.2690 - val_loss: 0.0618 - val_mean_squared_error: 0.0618 - val_accuracy: 0.2798\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0574 - mean_squared_error: 0.0574 - accuracy: 0.3231 - val_loss: 0.0592 - val_mean_squared_error: 0.0592 - val_accuracy: 0.2941\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0549 - mean_squared_error: 0.0549 - accuracy: 0.3452 - val_loss: 0.0561 - val_mean_squared_error: 0.0561 - val_accuracy: 0.3375\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0526 - mean_squared_error: 0.0526 - accuracy: 0.3542 - val_loss: 0.0551 - val_mean_squared_error: 0.0551 - val_accuracy: 0.4460\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0510 - mean_squared_error: 0.0510 - accuracy: 0.3546 - val_loss: 0.0517 - val_mean_squared_error: 0.0517 - val_accuracy: 0.3589\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0494 - mean_squared_error: 0.0494 - accuracy: 0.3679 - val_loss: 0.0516 - val_mean_squared_error: 0.0516 - val_accuracy: 0.3662\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - accuracy: 0.3703 - val_loss: 0.0499 - val_mean_squared_error: 0.0499 - val_accuracy: 0.3715\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0462 - mean_squared_error: 0.0462 - accuracy: 0.3657 - val_loss: 0.0475 - val_mean_squared_error: 0.0475 - val_accuracy: 0.3448\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - accuracy: 0.3770 - val_loss: 0.0456 - val_mean_squared_error: 0.0456 - val_accuracy: 0.4431\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0438 - mean_squared_error: 0.0438 - accuracy: 0.3768 - val_loss: 0.0445 - val_mean_squared_error: 0.0445 - val_accuracy: 0.4100\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0431 - mean_squared_error: 0.0431 - accuracy: 0.3846 - val_loss: 0.0441 - val_mean_squared_error: 0.0441 - val_accuracy: 0.4263\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - accuracy: 0.3853 - val_loss: 0.0437 - val_mean_squared_error: 0.0437 - val_accuracy: 0.3846\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - accuracy: 0.3934 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_accuracy: 0.4042\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0408 - mean_squared_error: 0.0408 - accuracy: 0.3988 - val_loss: 0.0428 - val_mean_squared_error: 0.0428 - val_accuracy: 0.4555\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - accuracy: 0.4046 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_accuracy: 0.3842\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - accuracy: 0.4121 - val_loss: 0.0403 - val_mean_squared_error: 0.0403 - val_accuracy: 0.4058\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - accuracy: 0.4153 - val_loss: 0.0403 - val_mean_squared_error: 0.0403 - val_accuracy: 0.3974\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - accuracy: 0.4218 - val_loss: 0.0397 - val_mean_squared_error: 0.0397 - val_accuracy: 0.4460\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - accuracy: 0.4300 - val_loss: 0.0389 - val_mean_squared_error: 0.0389 - val_accuracy: 0.4564\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - accuracy: 0.4339 - val_loss: 0.0396 - val_mean_squared_error: 0.0396 - val_accuracy: 0.4152\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - accuracy: 0.4390 - val_loss: 0.0395 - val_mean_squared_error: 0.0395 - val_accuracy: 0.3889\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - accuracy: 0.4454 - val_loss: 0.0384 - val_mean_squared_error: 0.0384 - val_accuracy: 0.4386\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - accuracy: 0.4449 - val_loss: 0.0391 - val_mean_squared_error: 0.0391 - val_accuracy: 0.4523\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - accuracy: 0.4523 - val_loss: 0.0387 - val_mean_squared_error: 0.0387 - val_accuracy: 0.4535\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - accuracy: 0.4557 - val_loss: 0.0375 - val_mean_squared_error: 0.0375 - val_accuracy: 0.4616\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - accuracy: 0.4567 - val_loss: 0.0377 - val_mean_squared_error: 0.0377 - val_accuracy: 0.4789\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - accuracy: 0.4606 - val_loss: 0.0383 - val_mean_squared_error: 0.0383 - val_accuracy: 0.4842\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - accuracy: 0.4644 - val_loss: 0.0369 - val_mean_squared_error: 0.0369 - val_accuracy: 0.4971\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - accuracy: 0.4636 - val_loss: 0.0373 - val_mean_squared_error: 0.0373 - val_accuracy: 0.4545\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - accuracy: 0.4653 - val_loss: 0.0367 - val_mean_squared_error: 0.0367 - val_accuracy: 0.4450\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - accuracy: 0.4684 - val_loss: 0.0371 - val_mean_squared_error: 0.0371 - val_accuracy: 0.4716\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - accuracy: 0.4694 - val_loss: 0.0365 - val_mean_squared_error: 0.0365 - val_accuracy: 0.4516\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - accuracy: 0.4692 - val_loss: 0.0372 - val_mean_squared_error: 0.0372 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - accuracy: 0.4713 - val_loss: 0.0370 - val_mean_squared_error: 0.0370 - val_accuracy: 0.4411\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - accuracy: 0.4658 - val_loss: 0.0363 - val_mean_squared_error: 0.0363 - val_accuracy: 0.4742\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - accuracy: 0.4650 - val_loss: 0.0365 - val_mean_squared_error: 0.0365 - val_accuracy: 0.4669\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - accuracy: 0.4667 - val_loss: 0.0365 - val_mean_squared_error: 0.0365 - val_accuracy: 0.4579\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - accuracy: 0.4683 - val_loss: 0.0358 - val_mean_squared_error: 0.0358 - val_accuracy: 0.4843\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - accuracy: 0.4723 - val_loss: 0.0358 - val_mean_squared_error: 0.0358 - val_accuracy: 0.4703\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - accuracy: 0.4703 - val_loss: 0.0358 - val_mean_squared_error: 0.0358 - val_accuracy: 0.4874\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - accuracy: 0.4693 - val_loss: 0.0366 - val_mean_squared_error: 0.0366 - val_accuracy: 0.4570\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - accuracy: 0.4676 - val_loss: 0.0363 - val_mean_squared_error: 0.0363 - val_accuracy: 0.4366\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - accuracy: 0.4717 - val_loss: 0.0355 - val_mean_squared_error: 0.0355 - val_accuracy: 0.4608\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - accuracy: 0.4747 - val_loss: 0.0354 - val_mean_squared_error: 0.0354 - val_accuracy: 0.4368\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - accuracy: 0.4748 - val_loss: 0.0352 - val_mean_squared_error: 0.0352 - val_accuracy: 0.4786\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - accuracy: 0.4736 - val_loss: 0.0351 - val_mean_squared_error: 0.0351 - val_accuracy: 0.5006\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - accuracy: 0.4713 - val_loss: 0.0368 - val_mean_squared_error: 0.0368 - val_accuracy: 0.4552\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - accuracy: 0.4742 - val_loss: 0.0352 - val_mean_squared_error: 0.0352 - val_accuracy: 0.4897\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - accuracy: 0.4740 - val_loss: 0.0351 - val_mean_squared_error: 0.0351 - val_accuracy: 0.4868\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - accuracy: 0.4707 - val_loss: 0.0358 - val_mean_squared_error: 0.0358 - val_accuracy: 0.4775\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - accuracy: 0.4675 - val_loss: 0.0348 - val_mean_squared_error: 0.0348 - val_accuracy: 0.5056\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 13s 259ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - accuracy: 0.4619 - val_loss: 0.0365 - val_mean_squared_error: 0.0365 - val_accuracy: 0.4907\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - accuracy: 0.4710 - val_loss: 0.0349 - val_mean_squared_error: 0.0349 - val_accuracy: 0.4830\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - accuracy: 0.4619 - val_loss: 0.0350 - val_mean_squared_error: 0.0350 - val_accuracy: 0.4783\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - accuracy: 0.4600 - val_loss: 0.0354 - val_mean_squared_error: 0.0354 - val_accuracy: 0.4410\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - accuracy: 0.4597 - val_loss: 0.0347 - val_mean_squared_error: 0.0347 - val_accuracy: 0.4906\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - accuracy: 0.4607 - val_loss: 0.0344 - val_mean_squared_error: 0.0344 - val_accuracy: 0.4693\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - accuracy: 0.4543 - val_loss: 0.0343 - val_mean_squared_error: 0.0343 - val_accuracy: 0.4738\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - accuracy: 0.4510 - val_loss: 0.0350 - val_mean_squared_error: 0.0350 - val_accuracy: 0.4777\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - accuracy: 0.4514 - val_loss: 0.0345 - val_mean_squared_error: 0.0345 - val_accuracy: 0.4855\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - accuracy: 0.4516 - val_loss: 0.0348 - val_mean_squared_error: 0.0348 - val_accuracy: 0.4416\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - accuracy: 0.4424 - val_loss: 0.0348 - val_mean_squared_error: 0.0348 - val_accuracy: 0.4568\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - accuracy: 0.4371 - val_loss: 0.0341 - val_mean_squared_error: 0.0341 - val_accuracy: 0.4603\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - accuracy: 0.4401 - val_loss: 0.0338 - val_mean_squared_error: 0.0338 - val_accuracy: 0.4596\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - accuracy: 0.4301 - val_loss: 0.0344 - val_mean_squared_error: 0.0344 - val_accuracy: 0.4692\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - accuracy: 0.4247 - val_loss: 0.0341 - val_mean_squared_error: 0.0341 - val_accuracy: 0.4547\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - accuracy: 0.4181 - val_loss: 0.0381 - val_mean_squared_error: 0.0381 - val_accuracy: 0.4141\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - accuracy: 0.4162 - val_loss: 0.0348 - val_mean_squared_error: 0.0348 - val_accuracy: 0.4377\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - accuracy: 0.4176 - val_loss: 0.0345 - val_mean_squared_error: 0.0345 - val_accuracy: 0.4241\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - accuracy: 0.4181 - val_loss: 0.0344 - val_mean_squared_error: 0.0344 - val_accuracy: 0.4295\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - accuracy: 0.4164 - val_loss: 0.0338 - val_mean_squared_error: 0.0338 - val_accuracy: 0.4146\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - accuracy: 0.4128 - val_loss: 0.0336 - val_mean_squared_error: 0.0336 - val_accuracy: 0.4141\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - accuracy: 0.4094 - val_loss: 0.0336 - val_mean_squared_error: 0.0336 - val_accuracy: 0.4263\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - accuracy: 0.4053 - val_loss: 0.0334 - val_mean_squared_error: 0.0334 - val_accuracy: 0.4217\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - accuracy: 0.3984 - val_loss: 0.0337 - val_mean_squared_error: 0.0337 - val_accuracy: 0.4305\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - accuracy: 0.3956 - val_loss: 0.0336 - val_mean_squared_error: 0.0336 - val_accuracy: 0.4059\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - accuracy: 0.3932 - val_loss: 0.0335 - val_mean_squared_error: 0.0335 - val_accuracy: 0.4102\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - accuracy: 0.3933 - val_loss: 0.0332 - val_mean_squared_error: 0.0332 - val_accuracy: 0.3950\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - accuracy: 0.3890 - val_loss: 0.0339 - val_mean_squared_error: 0.0339 - val_accuracy: 0.3941\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - accuracy: 0.3814 - val_loss: 0.0331 - val_mean_squared_error: 0.0331 - val_accuracy: 0.3965\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - accuracy: 0.3840 - val_loss: 0.0331 - val_mean_squared_error: 0.0331 - val_accuracy: 0.3960\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - accuracy: 0.3797 - val_loss: 0.0330 - val_mean_squared_error: 0.0330 - val_accuracy: 0.4188\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - accuracy: 0.3782 - val_loss: 0.0329 - val_mean_squared_error: 0.0329 - val_accuracy: 0.3872\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - accuracy: 0.3722 - val_loss: 0.0336 - val_mean_squared_error: 0.0336 - val_accuracy: 0.3847\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - accuracy: 0.3606 - val_loss: 0.0329 - val_mean_squared_error: 0.0329 - val_accuracy: 0.3645\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - accuracy: 0.3661 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_accuracy: 0.3876\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - accuracy: 0.3687 - val_loss: 0.0331 - val_mean_squared_error: 0.0331 - val_accuracy: 0.3641\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - accuracy: 0.3583 - val_loss: 0.0324 - val_mean_squared_error: 0.0324 - val_accuracy: 0.3603\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - accuracy: 0.3535 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_accuracy: 0.3529\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - accuracy: 0.3519 - val_loss: 0.0324 - val_mean_squared_error: 0.0324 - val_accuracy: 0.3548\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - accuracy: 0.3450 - val_loss: 0.0322 - val_mean_squared_error: 0.0322 - val_accuracy: 0.3443\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - accuracy: 0.3482 - val_loss: 0.0324 - val_mean_squared_error: 0.0324 - val_accuracy: 0.3462\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - accuracy: 0.3418 - val_loss: 0.0320 - val_mean_squared_error: 0.0320 - val_accuracy: 0.3487\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - accuracy: 0.3428 - val_loss: 0.0322 - val_mean_squared_error: 0.0322 - val_accuracy: 0.3508\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - accuracy: 0.3356 - val_loss: 0.0322 - val_mean_squared_error: 0.0322 - val_accuracy: 0.3650\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - accuracy: 0.3360 - val_loss: 0.0322 - val_mean_squared_error: 0.0322 - val_accuracy: 0.3602\n",
      "Saving math-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 08:19:24.796986: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/c42slkls67q1v67xnn3n9bx80000gn/T/ipykernel_38931/3314448077.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m do_training(ml_env, math_model, train, val, math_data, epochs_per_cycle, model_path=model_path, \n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mweights_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             regenerate_data_after_cycles=regenerate_data_after_cycles, data_func=create_train_val_data_regen, log_path=log_path)\n",
      "\u001b[0;32m/var/folders/9j/c42slkls67q1v67xnn3n9bx80000gn/T/ipykernel_38931/2278263529.py\u001b[0m in \u001b[0;36mdo_training\u001b[0;34m(mlenv, math_model, training_dataset, validation_dataset, math_data, epochs_per_cycle, model_path, weights_file, test_model, cycles, steps_per_epoch, reweight_size, valid_ops, regenerate_data_after_cycles, data_func, log_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving math-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mmath_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Checking {reweight_size} datapoints for accuracy...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2143\u001b[0m     \"\"\"\n\u001b[1;32m   2144\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2146\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[1;32m    150\u001b[0m                             signatures, options, save_traces)\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_internal_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0m\u001b[1;32m     91\u001b[0m           model, filepath, signatures, options)\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1228\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1229\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1230\u001b[0m       pywrap_libexport.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m   \u001b[0;31m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m   saveable_view = _SaveableView(checkpoint_graph_view, options,\n\u001b[0m\u001b[1;32m   1349\u001b[0m                                 wrapped_functions)\n\u001b[1;32m   1350\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_view, options, wrapped_functions)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# Run through the nodes in the object graph first for side effects of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# creating variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_all_concrete_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     (self._trackable_objects, self.node_paths, self._node_ids,\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_trace_all_concrete_functions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0mon\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mlist_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;34m\"\"\"Traverse the object graph and list all accessible objects.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0mtrackable_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects_ids_and_slot_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrackable_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mobjects_ids_and_slot_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mobjects_ids_and_slot_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     trackable_objects, _, node_ids, slot_variables = (\n\u001b[0;32m--> 455\u001b[0;31m         self.objects_ids_and_slot_variables_and_paths())\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrackable_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mobjects_ids_and_slot_variables_and_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mobject_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_to_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m       \u001b[0mobject_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_object_prefix_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0mnode_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36m_object_prefix_from_path\u001b[0;34m(path_to_root)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_object_prefix_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   return \"/\".join(\n\u001b[0m\u001b[1;32m     63\u001b[0m       (_escape_local_name(trackable.name)\n\u001b[1;32m     64\u001b[0m        for trackable in path_to_root))\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_object_prefix_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   return \"/\".join(\n\u001b[0;32m---> 63\u001b[0;31m       (_escape_local_name(trackable.name)\n\u001b[0m\u001b[1;32m     64\u001b[0m        for trackable in path_to_root))\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36m_escape_local_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;31m# edges traversed to reach the variable, so we escape forward slashes in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;31m# names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m   return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)\n\u001b[0m\u001b[1;32m     58\u001b[0m           .replace(r\"/\", _ESCAPE_CHAR + \"S\"))\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "do_training(ml_env, math_model, train, val, math_data, epochs_per_cycle, model_path=model_path, \n",
    "            weights_file=weights_file, test_model=test_model, cycles=cycles, steps_per_epoch=steps_per_epoch, valid_ops=valid_ops, \n",
    "            regenerate_data_after_cycles=regenerate_data_after_cycles, data_func=create_train_val_data_regen, log_path=log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oO6dRCu6TJqm"
   },
   "source": [
    "# Testing and applying the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hcGr9h_p9_R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ml_env.is_tpu is False:\n",
    "    test_model = math_model\n",
    "math_data.check_results(test_model, samples=100, valid_ops=valid_ops, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bv8ZRa8GpThA"
   },
   "outputs": [],
   "source": [
    "dx,dy,_,_,_=math_data.create_data_point(22,33,'*'); print(22*33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZt0CbNdqpqW"
   },
   "outputs": [],
   "source": [
    "r=test_model.predict(np.array([dx]))\n",
    "print(r)\n",
    "math_data.decode_results(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QV52DL3gq0rI"
   },
   "outputs": [],
   "source": [
    "def calc(inp):\n",
    "    args=inp.split(' ')\n",
    "    if len(args)!=3:\n",
    "        print(\"need three space separated tokens: <int> <operator> <int>, e.g. '3 + 4' or '4 XOR 5'\")\n",
    "        return False\n",
    "    if args[1] not in math_data.model_ops:\n",
    "        print(f\"{args[1]} is not a known operator.\")\n",
    "        return False\n",
    "    op1=int(args[0])\n",
    "    op2=int(args[2])\n",
    "    dx,dy,_,_,_=math_data.create_data_point(op1, op2, args[1])\n",
    "    ans=math_data.decode_results(test_model.predict(np.array([dx])))\n",
    "    print(f\"{op1} {args[1]} {op2} = {ans[0]}\")\n",
    "    op=f\"{op1} {args[1]} {op2}\"\n",
    "    op=op.replace('AND', '&').replace('XOR','^').replace('=','==').replace('OR','|')\n",
    "    an2=eval(op)\n",
    "    if ans[0]!=an2:\n",
    "        print(\"Error\")\n",
    "        print(bin(ans[0]))\n",
    "        print(bin(an2))\n",
    "    return ans[0],an2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeqeW9hlrEEE"
   },
   "outputs": [],
   "source": [
    "calc(\"22 * 33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0jjSQodrH0s"
   },
   "outputs": [],
   "source": [
    "calc(\"1 = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoK-LUr-s9IO"
   },
   "outputs": [],
   "source": [
    "calc(\"3 * 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frQNAv4Fs-_w"
   },
   "outputs": [],
   "source": [
    "calc (\"1 AND 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL8L83LllnoZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "ALU_Net.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
